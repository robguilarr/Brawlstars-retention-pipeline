# You can define spark specific configuration here.
spark.driver.maxResultSize: 12g
spark.driver.memory: 14g
spark.executor.memory: 14g
# spark.sql.shuffle.partitions: 100
# spark.default.parallelism: 100
spark.hadoop.fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
spark.sql.adaptive.enabled: true
spark.sql.adaptive.coalescePartitions.enabled: true
spark.sql.execution.arrow.pyspark.enabled: true
spark.history.ui.port: 18080
spark.sql.legacy.timeParserPolicy: LEGACY

# https://kedro.readthedocs.io/en/stable/tools_integration/pyspark.html#tips-for-maximising-concurrency-using-threadrunner
spark.scheduler.mode: FAIR